# [YoloV3](https://blog.csdn.net/weixin_44791964/article/details/105310627)

![image-20211025155947205](学习笔记.assets/image-20211025155947205.png)

## 1 主干特征提取网络

> [batch_size, 416, 416,3]

> Conv2D 32*3*3 [batch_size, 416,416,32]

> Residual Block 1 * 64 [batch_size, 208, 208, 64]

> Residual Block 2 * 128 [batch_size, 104, 104, 128]

> Residual Block1 8 * 256 [batch_size, 52, 52, 256]

> Residual Block2 8 * 512 [batch_size, 26, 26, 512]

> Residual Block3 8 * 512 [batch_size, 13, 13, 1024]



## 2 将下3层的特征传入下一阶段

Block3进行5次卷积运算，

> Conv2D Block 5 1024 [batch_size, 13,13,1024]



### 2.1 Block3



#### 2.1.1 方向1

预测和回归

> Conv2D 3*3 +Conv2D 1*1 [batch_size, 13, 13, 75] [batch_size, 13, 13, 3, 20+1+4]

其中，20是预测的种类，1是是否包含物体，4是调整参数（位置）



#### 2.1.2 方向2

上采样，之后与block2进行堆叠

> Conv2D + UpSampling2D [batch_size, 26, 26, 256]

> Concat [batch_size, 26, 26, 512+256]

目的：利用特征金字塔，可以进行多尺度的特征融合，提取出更有效的特征。

堆叠后进行5次卷积运算，

> Conv2D Block 5 256 [batch_size, 26,26,256]

> Conv2D 3*3 +Conv2D 1*1 [batch_size, 26, 26, 75] [batch_size, 26, 26, 3, 20+1+4]



### 2.2 Blcok1

将方向2 的结果卷积和上采样后，进行堆叠。
在继续卷积为52*52*75



## 3 特征获取预测结果的过程

该过程开业分为两部分，分别是构建FPN特征金字塔进行加强特征提取和利用YoloHead对三个有效特征层进行预测。



### 3.1 构建FPN特征金字塔进行加强特征提取

在特征利用部分，YoloV3提取**多特征层**进行目标检测，一共提取了三个。
提取的是DarkNet53的中间层、中下层和底层。（此处不能解释为倒数三层，因为其中很多重复的层）。



```python
ResidualOut3.shape = [batch_size, 52, 52, 256]
ResidualOut4.shape = [batch_size, 26, 26, 512]
ResidualOut5.shape = [batch_size, 13, 13, 1024]
```



#### 3.1.1 构建方式

- **ResidualOut5**特征层进行5次卷积，处理完后，一边利用YoloHead获得预测结果；另一方面进行上采样，UpSampling2d，与**ResidualOut4**进行拼接，得到[batch_size, 26, 26, 768]
- 结合后（[batch_size, 26, 26, 768]）的特征层再进行5次卷积，一边利用YoloHead获得预测结果，另一方面进行上采样，结果与**ResidualOut3**进行结合。
- 将结合后的**ResidualOut3**，进行5次卷积处理，处理完后利用YoloHead获得预测结果。



### 3.2 利用Yolo Head对三个有效的特征层进行预测

- 利用FPN特征金字塔，可以获得三个加强特征，并传入yolohead进行处理。
  - [13, 13, 75]
  - [26, 26, 75]
  - [52, 52, 75]
- 其中，75表示：
  - 他的类有20种，1个维度表示是否有物体，4个维度表示坐标， 25=20+1+4。 YoloV3针对每一个特征层的每一个特征点，存在3个先验框，所以 75 = 3*25。
  - 如果种类有80个，则维度为85*3 = 255。

## 4  解码

4+1+20分别表示：

- x_offset
- y_offset
- h
- w
- 置信度
- 分类结果

但是，这个结果并不会对应最终的预测框在图片上的位置，还需要解码才能完成。

得到的最终预测结果还要进行**得分排序和非极大值抑制**进行筛选。



### 4.1 输入

解码的输入为第3部分输出，一共3个，大小分别为：

- [13, 13, 75]
- [26, 26, 75]
- [52, 52, 75]

对每一个结果，都要分别执行操作。

### 4.2 解码过程

- 获取输入部分的batch_size，长和宽，由于torch中使用的是batch_size, channel, height, weight

```python
batch_size   = input.size(0)
input_height = input.size(2)
input_width  = input.size(3)
```

- 求步长：将原始图像分为13*13的大小，每个块的长和宽就是步长。

```python
stride_h = self.input_shape[0] / input_height
stride_w = self.input_shape[1] / input_width
```

- <font color = red>计算scaled_anchors（此处还未理解。）</font>

```python
scaled_anchors = [(anchor_width / stride_w, anchor_height / stride_h) for anchor_width, anchor_height in self.anchors[self.anchors_mask[i]]]
```



- 将input（input是获取的一个特征，包含种类，是否有物体和坐标信息）变为prediction。prediction的大小为[batch_size, 3, 25, 13,13]。input的大小为[batch_size, 75, 13, 13]。同时，将特征信息维度，即25，放置到最后，方便特征的分解。

```python
prediction = input.view(batch_size, len(self.anchors_mask[i]), self.bbox_attrs, input_height, input_width).permute(0, 1, 3, 4, 2).contiguous()
```

- 特征分解
  - 25=4+1+20（4：先验框中心x,y，先验框h,w；1：是否有物体；20：种类）。

![image-20211027153613156](学习笔记.assets/image-20211027153613156.png)

```python
x = torch.sigmoid(prediction[..., 0]) 
y = torch.sigmoid(prediction[..., 1])
w = prediction[..., 2]
h = prediction[..., 3]

conf        = torch.sigmoid(prediction[..., 4])
pred_cls    = torch.sigmoid(prediction[..., 5:])
```

- 生成网格-先验框，以左上角为基准。
  - linspace（下限，上限，段数）：将下限-上限分为x段，每段等长，返回一维tensor。
  - repeat(x,y)：将第一个维度重复x次，第2个维度重复y次。
  - view：最后将生成的矩阵，与x的大小变为一致。
  - t()：转置，0-12由横向变为竖向。

```python
grid_x = torch.linspace(0, input_width - 1, input_width).repeat(input_height, 1).repeat(batch_size * len(self.anchors_mask[i]), 1, 1).view(x.shape).type(FloatTensor)

grid_y = torch.linspace(0, input_height - 1, input_height).repeat(input_width, 1).t().repeat(batch_size * len(self.anchors_mask[i]), 1, 1).view(y.shape).type(FloatTensor)
```

![image-20211025215221537](学习笔记.assets/image-20211025215221537.png)



- 生成先验框的宽高
  - 根据代码，计算结果应当是一个数据的重复，宽为一个数，高位一个数。
  - w和h的shape = [batch_size, 13, 13]。即，每个块的宽和高都可以找到对应的值，而且一致。

```python
anchor_w = FloatTensor(scaled_anchors).index_select(1, LongTensor([0]))
anchor_h = FloatTensor(scaled_anchors).index_select(1, LongTensor([1]))
anchor_w = anchor_w.repeat(batch_size, 1).repeat(1, 1, input_height * input_width).view(w.shape)
anchor_h = anchor_h.repeat(batch_size, 1).repeat(1, 1, input_height * input_width).view(h.shape)
```

- 利用预测结果对先验框进行调整
  - pred_boxes.shape = [batch_size, 13,13, 4]
  - <font color=red>此处不是十分理解</font>：
    - 先调整先验框的中心，向右下角偏移。
    - 再调整先验框的宽高。

```python
pred_boxes = FloatTensor(prediction[..., :4].shape)
pred_boxes[..., 0]  = x.data + grid_x
pred_boxes[..., 1]  = y.data + grid_y
pred_boxes[..., 2]  = torch.exp(w.data) * anchor_w
pred_boxes[..., 3]  = torch.exp(h.data) * anchor_h
```

- 将输出归一化位小数，并将结果进行拼接。

```python
_scale = torch.Tensor([input_width, input_height, input_width, input_height]).type(FloatTensor)
output = torch.cat((pred_boxes.view(batch_size, -1, 4) / _scale, conf.view(batch_size, -1, 1), pred_cls.view(batch_size, -1, self.num_classes)), -1)
```

